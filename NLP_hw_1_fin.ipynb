{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327f47ed-6f1c-4365-8d3b-5b97d2e5ff7d",
   "metadata": {},
   "source": [
    "Харламова Дарья Сергеевна, БКЛ-212\n",
    "Домашнее задание 1.\n",
    "\n",
    "В данном блокноте мы займемся классификацией отзывов на положительные и отрицательные с помощью алгоритмического кода. В качестве \"подопытного\" выступит известный сайт \"Кинопоиск\", а разбирать мы будем рецензии на фильмы. \n",
    "\n",
    "Для начала импортируем все необходимые нам библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42eacf1b-e315-4f82-89ad-df281a0f63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from fake_useragent import UserAgent\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem\n",
    "import itertools\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9aa3d4-f028-4db2-9a3d-62c39fab4684",
   "metadata": {},
   "source": [
    "Первым шагом займемся парсингом данных. Создадим сессию. Выяснив, что \"Кинопоиск\" быть подопытным не хочет, а вместо этого хочет банить наши запросы как подозрительные и подсовывать нам капчу, притворимся браузером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b402391-de3b-4c3e-ae73-ded624bb294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "ua = UserAgent(browsers = [\"chrome\", \"edge\", \"firefox\", \"safari\"])\n",
    "adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=10)\n",
    "session.mount('https://', adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7cb2c9-834f-41df-8a68-9e50e8874426",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет принимать на вход URL-адрес страницы с отзывами, а возвращать - список хороших и плохих отзывов, которые присутствуют на странице. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d367f2c-14cb-4aa2-bd0b-138f1271d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_bad_reviews(url):\n",
    "    positive_all_entries = []\n",
    "    negative_all_entries = []\n",
    "    response = session.get(url, headers={'User-Agent': ua.random})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    positive_all_entries = soup.find_all('div', {'class': 'response good'})\n",
    "    negative_all_entries = soup.find_all('div', {'class': 'response bad'})\n",
    "    return positive_all_entries, negative_all_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2510c-8be1-4fe5-b735-1a70278cdc77",
   "metadata": {},
   "source": [
    "Изначально мы хотели собрать рецензии на разные фильмы и проитерироваться по разным URL - но Кинопоиску кажется это подозрительным, поэтому пока ограничимся одним. Фильм нужен популярный (чтобы набрать большое количество отзывов сразу) и достаточно спорный, чтобы с него можно было собрать примерно равное количество положительных и отрицательных рецензий. Выбор на самом деле очевиден - \"Сумерки\"!\n",
    "\n",
    "Для быстрых модификаций - для сбора рецензий по большему количеству фильмов достаточно добавить URL-адреса \"Кинопоиска\" в список url_working (но обычно к обработке второй ссылки \"Кинопоиск\" уже выкидывает экран с капчей и сбегает, хохоча)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6abb42-6431-4f35-abd9-2407fcebdfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_working = [\"https://www.kinopoisk.ru/film/401177/reviews/ord/date/status/all/perpage/200/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343e370f-c227-4ad3-8262-43aa0743e3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_list = []\n",
    "neg_list = []\n",
    "control = []\n",
    "for link in url_working:\n",
    "    pair = get_good_bad_reviews(link)\n",
    "    pos_list.append(pair[0])\n",
    "    neg_list.append(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668c290-853c-4bd6-9f79-b6f75c105693",
   "metadata": {},
   "source": [
    "Отобрав у \"Кинопоиска\" рецензии, соберем положительные и отрицательные рецензии в один список и посмотрим на масштаб нашего \"улова\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3062dddc-0a51-4e6b-b607-7e42eda97993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_parse = list(itertools.chain.from_iterable(pos_list))\n",
    "neg_parse = list(itertools.chain.from_iterable(neg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcde0c25-9318-45d8-a832-9534870946e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_parse))\n",
    "print(len(neg_parse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7506c-ff14-47e2-a4e6-8cd6ee8fa220",
   "metadata": {},
   "source": [
    "Бинго - у нас практически равное количество положительных и отрицательных рецензий! Теперь отберем из них контрольную группу, оформив ее в словарик, где ключи - рецензии, а значения обозначают, положительной или отрицательной является рецензия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c96feb8-e9be-4ff6-b845-c44eb141c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_parse = {}\n",
    "for revieows in pos_parse[60:76]:\n",
    "    control_parse[revieows] = 'Positive'\n",
    "del pos_parse[60:76]\n",
    "for revieows in neg_parse[60:77]:\n",
    "    control_parse[revieows] = 'Negative'\n",
    "del neg_parse[60:77]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d62048-14dc-4376-9dc9-59ca5e8ded23",
   "metadata": {},
   "source": [
    "Посмотрим на итоговое количество рецензий, которые оказались в контрольной группе и в группах, по которым мы будем собирать словарики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef82da37-d25f-4581-acd0-9d19dce6c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(control_parse))\n",
    "print(len(pos_parse))\n",
    "print(len(neg_parse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9819772-b562-4a5c-838e-5a7bd2b64d64",
   "metadata": {},
   "source": [
    "Теперь начнем, собственно, собирание словариков. Для лемматизации будем пользоваться Mystem - создадим его объект. Еще в процессе очистки текста уберем из него стоп-слова: для этого импортируем из NLTK список русских стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759b2782-b3d5-49ff-b148-80b186e6aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66557b-4c96-4029-b285-7099c7dc1b69",
   "metadata": {},
   "source": [
    "Зададим функцию, которая будет очищать нам текст. На вход она получает обработанный \"супом\" HTML-объект и флажок, который обозначает, интересует ли нас целиковый текст. \n",
    "\n",
    "Если передать 1, то функция отдаст содержащийся в \"супе\" текст рецензии в немного причесанном виде\n",
    "\n",
    "Если передать 0, то функция вернет лемматизированный и токенизированный текст, по возможности очищенный от пунктуации. \n",
    "\n",
    "Для работы нам нужнен только 0, но возможность передать единицу присутствует для удобства демонстрации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e4054d-b28c-4568-964b-b32a8fa54e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review_soup, print_text):\n",
    "    word_list = []\n",
    "    review = str(review_soup.text)\n",
    "    review = review[review.find('звёзды')+6:review.rfind('прямая ссылка')]\n",
    "    review = review.strip()\n",
    "    review = review.replace('\\n', ' ')\n",
    "    review = review.replace('\\r', '')\n",
    "    if print_text == 1:\n",
    "        return review\n",
    "    if print_text == 0:\n",
    "        review = mystem.lemmatize(review.lower())\n",
    "        for token in review:\n",
    "            token = token.replace(' ', '')\n",
    "            if token != ' ' and token not in russian_stopwords and token not in punctuation:\n",
    "                word_list.append(token)\n",
    "        return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13451a38-9ddf-45b3-a9c9-b39b13155ff2",
   "metadata": {},
   "source": [
    "Пользуясь данной функцией, соберем для больших списка со всеми словами из положительных и отрицательных рецензий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9085a5a7-f38b-4af4-8481-d2a0a94c01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "neg_words = []\n",
    "for rev_g in pos_parse:\n",
    "    pos_words.append(process_review(rev_g, 0))\n",
    "for rev_n in neg_parse:\n",
    "    neg_words.append(process_review(rev_n, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3a18c-90e7-4111-b47e-7afc8799f5cc",
   "metadata": {},
   "source": [
    "Теперь напишем еще одну функцию - она будет получать на вход список из списков слов из каждой рецензии, соединять их в один, и сводить данные о частотности каждого слова в словарик, который и будет возвращаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45de8ecf-4a79-4f4d-9db7-c99a6e1ec1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_freq_list(words_list):\n",
    "    words_list = list(itertools.chain.from_iterable(words_list))\n",
    "    freqs = {}\n",
    "    for word in words_list:\n",
    "        freqs[word] = freqs.get(word, 0) + 1\n",
    "    return(freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d4ea5-1008-4a43-9000-5e719997486f",
   "metadata": {},
   "source": [
    "Получим словарики и отфильтруем их по частотности. Для того, чтобы быть достаточно объективными, будем учитывать слова, которые встретились суммарно не менее 10 раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe2ee73-702e-4450-979d-28ced77bd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_freq_words = {}\n",
    "for i in set_freq_list(pos_words).items():\n",
    "    if i[1] > 10:\n",
    "        pos_freq_words[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7254b380-46c5-47e2-b546-ce47c7e555f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_freq_words = {}\n",
    "for j in set_freq_list(neg_words).items():\n",
    "    if j[1] > 10:\n",
    "        neg_freq_words[j[0]] = j[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebaf6a1-bd72-4e61-8930-0ffc251fd902",
   "metadata": {},
   "source": [
    "Теперь из списка ключей наших словарей соберем множество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156de03b-e6d1-4952-8a61-dbf728cc4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words_set = set(pos_freq_words.keys())\n",
    "neg_words_set = set(neg_freq_words.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768ffd2-9c30-4dcf-beeb-58b5be8e6eab",
   "metadata": {},
   "source": [
    "Сохраним в переменные `pos_test` и `neg_test` элементы, которых нет в другом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a433b4b-dea8-4ab1-9b55-cc8c64247432",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test = pos_words_set.difference(neg_words_set)\n",
    "neg_test = neg_words_set.difference(pos_words_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12564fb4-cb8e-4abe-b3fa-01ae0cd1e39a",
   "metadata": {},
   "source": [
    "Теперь напишем функцию оценивания. На вход она должна принимать лемматизированный список слов, которые есть в рецензии. Итерируясь по этим словам, она ведет два счетчика, значение которых увеличивается на единицу с каждым словом, которое есть во множестве `pos_test` или `neg_test`. В зависимости от значений счетчиков функция принимает решение о том, является ли отзыв положительным или отрицательным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e329e67-d7ed-4e84-9d0d-ce24ddae3e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_stuff(rev):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    for slovo in rev:\n",
    "        if slovo in pos_test:\n",
    "            pos_score += 1\n",
    "        if slovo in neg_test:\n",
    "            neg_score += 1\n",
    "    if pos_score > neg_score:\n",
    "        return 'Positive'\n",
    "    if neg_score > pos_score:\n",
    "        return 'Negative'\n",
    "    if pos_score == neg_score:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cf8a1-cc2f-449d-b232-800aea181e9b",
   "metadata": {},
   "source": [
    "Прогоним наши тексты из контрольной группы через функции `process_review` и `evaluate_stuff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e1cc64-9135-4d97-b437-3e0f89f81f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Neutral',\n",
       " 'Negative',\n",
       " 'Neutral',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Neutral',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Positive']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for texts in control_parse:\n",
    "    test.append(evaluate_stuff(process_review(texts, 0)))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684f911-3ec0-43a5-8da0-aebb0e955ddc",
   "metadata": {},
   "source": [
    "Получим список истинных значений для контрольной группы, которые мы раньше сохранили в значениях словаря `control_parse`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6499f605-9d8f-4abe-9105-812834787d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = control_parse.values()\n",
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95503dc-1c24-4255-ade9-73e68b7d9fab",
   "metadata": {},
   "source": [
    "Посчитаем качество с помощью метрики `accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c08cc194-ebd9-4ff6-9e31-ee772cd5407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list(true), test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ace25-eb25-4c78-b9a5-c786e0ef8895",
   "metadata": {},
   "source": [
    "Итак, мы видим, что мы достигли сносной точности, но нам всё ещё есть куда расти. Например, можно попробовать учитывать более частотные слова с большим весом, чем менее частотные. Еще можно попробовать учитывать не только отдельные слова, а словосочетания из 2-3 элементов: это тоже может привести к большей точности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceebc0e-e341-4a89-9df9-7e3511531eb5",
   "metadata": {},
   "source": [
    "Попробуем в самом примитивном виде реализовать концепцию с весами. Сначала посмотрим, какие частоты у нас максимальные, обратившись к словарям с частотностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9b7e21-7491-4215-90aa-60ed00893af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(pos_freq_words.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "731d006e-472e-427d-a87c-e8bb390885dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(neg_freq_words.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3014c-f265-48c0-9947-de97fc271bb5",
   "metadata": {},
   "source": [
    "Теперь разобьем все слова на три класса по частотности. Допустим, самыми частотными будут считаться слова, которые встретились больше 150 раз, средними по частотности - слова, которые встретились от 50 до 150 раз, наименее частотными - слова, которые встретились меньше 50 раз. Распределим по этим категориям слова из оценочного множества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "678eb160-932f-4713-ad75-e9e14a777f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_max = []\n",
    "pos_test_mid = []\n",
    "pos_test_min = []\n",
    "for w in pos_test:\n",
    "    if pos_freq_words[w] > 150:\n",
    "        pos_test_max.append(w)\n",
    "    elif 50 < pos_freq_words[w] < 151:\n",
    "        pos_test_mid.append(w)\n",
    "    elif pos_freq_words[w] < 51:\n",
    "        pos_test_min.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d56ea6-2f84-4d98-a7de-9c2520b22aa9",
   "metadata": {},
   "source": [
    "Проверим, что никого не потеряли:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1ab3652-572e-4e75-80ea-c2f304050906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_test))\n",
    "print(len(pos_test_max) + len(pos_test_mid) + len(pos_test_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5a50c-abd6-4a70-b110-95e325854ad7",
   "metadata": {},
   "source": [
    "Повторим для негативных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28987875-38ae-4fd9-aeca-e80ba661b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test_max = []\n",
    "neg_test_mid = []\n",
    "neg_test_min = []\n",
    "for w in neg_test:\n",
    "    if neg_freq_words[w] > 150:\n",
    "        neg_test_max.append(w)\n",
    "    elif 50 < neg_freq_words[w] < 151:\n",
    "        neg_test_mid.append(w)\n",
    "    elif neg_freq_words[w] < 49:\n",
    "        neg_test_min.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01039bdb-365c-4ed6-aa33-76ada0b82be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_test))\n",
    "print(len(neg_test_max) + len(neg_test_mid) + len(neg_test_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34afd77b-6f94-48fc-a027-0ae0bda2dc94",
   "metadata": {},
   "source": [
    "Теперь зададим нашу функцию. Она очень похожа на функцию `evaluate_stuff`, но в зависимости от класса частотности, в который входит слово, приписывает положительному и отрицательному счетам разные количества очков. Так как предыдущий алгоритм скорее кренился в позитивные отзывы, немного усилим позиции негативных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c154fe5-706d-4741-a50d-a30d8bfa7eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stuff_w(rev):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    for slovo in rev:\n",
    "        if slovo in pos_test_max:\n",
    "            pos_score += 3\n",
    "        elif slovo in pos_test_mid:\n",
    "            pos_score += 2\n",
    "        elif slovo in pos_test_min:\n",
    "            pos_score += 1\n",
    "        elif slovo in neg_test_max:\n",
    "            neg_score += 3\n",
    "        elif slovo in neg_test_mid:\n",
    "            neg_score += 3\n",
    "        elif slovo in neg_test_min:\n",
    "            neg_score += 2\n",
    "    if pos_score > neg_score:\n",
    "        return 'Positive'\n",
    "    if neg_score > pos_score:\n",
    "        return 'Negative'\n",
    "    if pos_score == neg_score:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d1031d-e784-498f-a998-1e4d4e66a227",
   "metadata": {},
   "source": [
    "Проверим это наивное добавление на практике:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b294c4da-85c8-4e89-8157-1f5ff9954d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Negative',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Positive',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative',\n",
       " 'Negative']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for texts in control_parse:\n",
    "    test.append(evaluate_stuff_w(process_review(texts, 0)))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c285d63f-08b8-4612-9686-6c608e425a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = control_parse.values()\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be5039e9-28a0-433a-bb3a-0c7ca72592dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064516129032258"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list(true), test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c28f5-5196-470e-b8f4-fda681d7cf4d",
   "metadata": {},
   "source": [
    "Видим, что пусть наше добавление и было простым и невинным, на данной выборке точность оценивания немного подросла."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
